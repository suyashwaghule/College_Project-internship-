"""
Ethical & Societal Evaluation Module
=====================================
This module provides comprehensive ethical analysis and documentation
for the Predictive Policing Decision Support System.

Key Ethical Considerations:
1. Reporting Bias Impact on ML
2. Risks of Predictive Policing
3. Fairness and Equity
4. Transparency and Explainability
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


class EthicalEvaluator:
    """
    Evaluates ethical implications of crime prediction models
    """
    
    def __init__(self):
        self.ethical_report = []
        
    def analyze_reporting_bias(self, df, crime_col='TOTAL IPC CRIMES'):
        """
        Analyze potential reporting bias in the dataset
        
        Reporting bias occurs when:
        - Some states/districts over-report crimes
        - Some states/districts under-report crimes
        - Reporting practices vary over time
        """
        print("\n" + "=" * 60)
        print("ğŸ“Š REPORTING BIAS ANALYSIS")
        print("=" * 60)
        
        # Aggregate to state level
        state_df = df.groupby('STATE/UT')[crime_col].agg(['sum', 'mean', 'std', 'count'])
        state_df['cv'] = (state_df['std'] / state_df['mean']) * 100
        
        findings = []
        
        # 1. High variance within states suggests inconsistent reporting
        high_variance_states = state_df[state_df['cv'] > 100]
        if len(high_variance_states) > 0:
            findings.append({
                'type': 'High Intra-state Variance',
                'description': 'States with CV > 100% have highly inconsistent district-level reporting',
                'affected': list(high_variance_states.index),
                'risk': 'HIGH',
                'mitigation': 'Use state-level aggregation instead of district predictions'
            })
        
        # 2. Check for suspiciously low crime rates
        very_low = state_df[state_df['mean'] < state_df['mean'].quantile(0.1)]
        if len(very_low) > 0:
            findings.append({
                'type': 'Suspiciously Low Rates',
                'description': 'States with very low mean crime may indicate under-reporting',
                'affected': list(very_low.index),
                'risk': 'MEDIUM',
                'mitigation': 'Do not interpret low predictions as "safe" areas'
            })
        
        # 3. Check for outlier states
        z_scores = (state_df['sum'] - state_df['sum'].mean()) / state_df['sum'].std()
        outliers = state_df[np.abs(z_scores) > 2]
        if len(outliers) > 0:
            findings.append({
                'type': 'Statistical Outliers',
                'description': 'States with extreme values may skew model predictions',
                'affected': list(outliers.index),
                'risk': 'MEDIUM',
                'mitigation': 'Consider separate models for outlier states'
            })
        
        # Print findings
        for i, finding in enumerate(findings, 1):
            print(f"\nâš ï¸ Finding {i}: {finding['type']}")
            print(f"   Description: {finding['description']}")
            print(f"   Risk Level: {finding['risk']}")
            print(f"   Affected: {', '.join(finding['affected'][:5])}{'...' if len(finding['affected']) > 5 else ''}")
            print(f"   Mitigation: {finding['mitigation']}")
        
        self.ethical_report.extend(findings)
        return findings
    
    def generate_ethical_guidelines(self):
        """
        Generate ethical guidelines for using the prediction system
        """
        guidelines = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           ETHICAL GUIDELINES FOR SYSTEM USE                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                              â•‘
â•‘  1. PURPOSE LIMITATION                                       â•‘
â•‘     âœ“ Use ONLY for resource allocation planning              â•‘
â•‘     âœ“ Use for identifying areas needing social services      â•‘
â•‘     âœ— DO NOT use for targeting individuals                   â•‘
â•‘     âœ— DO NOT use for discriminatory practices                â•‘
â•‘                                                              â•‘
â•‘  2. INTERPRETATION GUIDELINES                                â•‘
â•‘     âœ“ HIGH risk = needs more community support               â•‘
â•‘     âœ“ LOW risk = may indicate under-reporting                â•‘
â•‘     âœ— DO NOT interpret as "dangerous" vs "safe" areas        â•‘
â•‘     âœ— DO NOT use for profiling communities                   â•‘
â•‘                                                              â•‘
â•‘  3. DATA LIMITATIONS                                         â•‘
â•‘     âœ“ Data reflects REPORTED crime only                      â•‘
â•‘     âœ“ Reporting rates vary by region and demographics        â•‘
â•‘     âœ“ Missing: population data, socioeconomic factors        â•‘
â•‘     âœ“ No individual-level data is used                       â•‘
â•‘                                                              â•‘
â•‘  4. TRANSPARENCY REQUIREMENTS                                â•‘
â•‘     âœ“ All predictions must include confidence levels         â•‘
â•‘     âœ“ Feature importance must be disclosed                   â•‘
â•‘     âœ“ Model limitations must accompany all outputs           â•‘
â•‘     âœ“ Regular bias audits are required                       â•‘
â•‘                                                              â•‘
â•‘  5. ACCOUNTABILITY                                           â•‘
â•‘     âœ“ Human review required before any action                â•‘
â•‘     âœ“ Appeals process for affected communities               â•‘
â•‘     âœ“ Regular model retraining with updated data             â•‘
â•‘     âœ“ External audit trails maintained                       â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        print(guidelines)
        return guidelines
    
    def analyze_predictive_policing_risks(self):
        """
        Document risks associated with predictive policing
        """
        risks = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         RISKS OF PREDICTIVE POLICING SYSTEMS                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                              â•‘
â•‘  ğŸ”´ HIGH RISK: Feedback Loops                                â•‘
â•‘     Problem: More policing â†’ more arrests â†’ "higher crime"   â•‘
â•‘     â†’ more policing (self-fulfilling prophecy)               â•‘
â•‘     Mitigation: Use crime REPORTS, not arrests; regular      â•‘
â•‘     bias audits                                              â•‘
â•‘                                                              â•‘
â•‘  ğŸ”´ HIGH RISK: Discrimination Amplification                  â•‘
â•‘     Problem: Historical bias in data gets encoded in ML      â•‘
â•‘     Mitigation: State-level only; no demographic features;   â•‘
â•‘     balanced class weights                                   â•‘
â•‘                                                              â•‘
â•‘  ğŸŸ¡ MEDIUM RISK: Over-reliance on Predictions                â•‘
â•‘     Problem: Decision-makers may trust ML over judgment      â•‘
â•‘     Mitigation: Mandatory human review; confidence scores;   â•‘
â•‘     clear uncertainty communication                          â•‘
â•‘                                                              â•‘
â•‘  ğŸŸ¡ MEDIUM RISK: Privacy Concerns                            â•‘
â•‘     Problem: Detailed predictions could identify individuals â•‘
â•‘     Mitigation: Aggregate to state level; no individual      â•‘
â•‘     predictions; no demographic profiling                    â•‘
â•‘                                                              â•‘
â•‘  ğŸŸ¢ LOW RISK (in this system): Individual Targeting          â•‘
â•‘     Status: MITIGATED by design                              â•‘
â•‘     How: Only state/district level predictions; no personal  â•‘
â•‘     data; focus on resource allocation                       â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        print(risks)
        return risks
    
    def justify_state_level_analysis(self):
        """
        Provide justification for state-level analysis approach
        """
        justification = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      JUSTIFICATION FOR STATE-LEVEL ANALYSIS                  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                              â•‘
â•‘  WHY STATE-LEVEL (not individual/neighborhood)?              â•‘
â•‘                                                              â•‘
â•‘  1. ETHICAL PROTECTION                                       â•‘
â•‘     â€¢ Prevents individual profiling                          â•‘
â•‘     â€¢ Reduces discrimination risk                            â•‘
â•‘     â€¢ Cannot be used for stop-and-frisk policies             â•‘
â•‘                                                              â•‘
â•‘  2. DATA QUALITY                                             â•‘
â•‘     â€¢ Aggregation smooths reporting inconsistencies          â•‘
â•‘     â€¢ Reduces impact of local data errors                    â•‘
â•‘     â€¢ More stable statistical estimates                      â•‘
â•‘                                                              â•‘
â•‘  3. APPROPRIATE USE CASE                                     â•‘
â•‘     â€¢ Budget allocation across states                        â•‘
â•‘     â€¢ Policy planning at government level                    â•‘
â•‘     â€¢ Social program targeting by region                     â•‘
â•‘                                                              â•‘
â•‘  4. LEGAL COMPLIANCE                                         â•‘
â•‘     â€¢ Aligns with privacy regulations                        â•‘
â•‘     â€¢ No personally identifiable information                 â•‘
â•‘     â€¢ Transparent and auditable                              â•‘
â•‘                                                              â•‘
â•‘  WHAT THIS SYSTEM CANNOT DO:                                 â•‘
â•‘  âœ— Predict crime for specific neighborhoods                  â•‘
â•‘  âœ— Identify "high-risk" individuals                          â•‘
â•‘  âœ— Guide patrol routes                                       â•‘
â•‘  âœ— Support arrest decisions                                  â•‘
â•‘                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        print(justification)
        return justification
    
    def generate_full_report(self, df):
        """
        Generate comprehensive ethical evaluation report
        """
        print("\n" + "=" * 60)
        print("ğŸ“‹ COMPREHENSIVE ETHICAL EVALUATION REPORT")
        print("   Predictive Policing Decision Support System")
        print("=" * 60)
        
        # 1. Reporting bias analysis
        self.analyze_reporting_bias(df)
        
        # 2. Risks
        self.analyze_predictive_policing_risks()
        
        # 3. Justification
        self.justify_state_level_analysis()
        
        # 4. Guidelines
        self.generate_ethical_guidelines()
        
        print("\n" + "=" * 60)
        print("âœ… Ethical Evaluation Complete")
        print("   This report should accompany all model deployments")
        print("=" * 60)


def main():
    """Run ethical evaluation"""
    # Load data
    df = pd.read_csv("data/raw/dstrIPC_2013.csv")
    
    # Initialize evaluator
    evaluator = EthicalEvaluator()
    
    # Generate full report
    evaluator.generate_full_report(df)


if __name__ == "__main__":
    main()
